{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def merge_spaces(input_string):\n",
    "    output_string = re.sub(r'\\s+', ' ', input_string)\n",
    "    return output_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### eLife Dataset Process (to the plos jsonl format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file_path = './datasets/elife/test.json'\n",
    "with open(file_path, 'r') as file:\n",
    "    json_objs = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "\n",
    "edatas = []\n",
    "\n",
    "for json_obj in json_objs:\n",
    "\n",
    "    edata = {}\n",
    "\n",
    "    abstract = ' '.join(json_obj['abstract']).replace('\\n',' ')\n",
    "    lay = ' '.join(json_obj['summary']).replace('\\n',' ')\n",
    "\n",
    "    assert len(json_obj[\"sections\"]) == len(json_obj['headings'])\n",
    "    cur_articles = []\n",
    "    for nid, (article_list, heading) in enumerate(zip(json_obj[\"sections\"],json_obj['headings'])):\n",
    "\n",
    "        cur_articles.append(str(nid+1) + ' ' + heading + ' ' + ' '.join(article_list).replace('\\n',' '))\n",
    "\n",
    "    edata['doi'] = json_obj['id']\n",
    "    edata['abstract'] = abstract\n",
    "    edata['plain language summary'] = lay\n",
    "    edata['article'] = ' '.join(cur_articles)\n",
    "\n",
    "    edatas.append(edata)\n",
    "\n",
    "\n",
    "with jsonlines.open('./datasets/elife/test_elife.jsonl', 'w') as writer:\n",
    "    for edata in edatas:\n",
    "        writer.write(edata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### extract instance's article (both datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# import textstat\n",
    "\n",
    "plos_datas_ts = []\n",
    "with open('./datasets/plos/test_plos.jsonl', 'r', encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "    # print(len(lines)) 26214\n",
    "    for lid in range(len(lines)):\n",
    "        data = json.loads(lines[lid])\n",
    "        plos_datas_ts.append(data)\n",
    "\n",
    "\n",
    "elife_datas_ts = []\n",
    "with open('./datasets/elife/test_elife.jsonl', 'r', encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "    # print(len(lines)) \n",
    "    for lid in range(len(lines)):\n",
    "        data = json.loads(lines[lid])\n",
    "        elife_datas_ts.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./datasets/elife/elife_testset.txt', 'a+', encoding=\"utf-8\") as f:\n",
    "    for data in elife_datas_ts:\n",
    "        f.write(data['article'].strip() + '\\n')\n",
    "\n",
    "with open('./datasets/plos/plos_testset.txt', 'a+', encoding=\"utf-8\") as f:\n",
    "    for data in plos_datas_ts:\n",
    "        f.write(merge_spaces(data['article'].replace('\\n',' ')).strip() + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate each QA in predicted QA pairs score with the reference of golden summaries (for ablation study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# import textstat\n",
    "\n",
    "gdatas = []\n",
    "with open('./datasets/plos/test_plos.jsonl', 'r', encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "    # print(len(lines)) 26214\n",
    "    for lid in range(len(lines)):\n",
    "        data = json.loads(lines[lid])\n",
    "        gdatas.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "import numpy as np\n",
    "\n",
    "def calc_rouge(preds, refs):\n",
    "  # Get ROUGE F1 scores\n",
    "  scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeLsum'], \\\n",
    "                                    use_stemmer=True, split_summaries=True)\n",
    "  scores = [scorer.score(p, refs[i]) for i, p in enumerate(preds)]\n",
    "  # print([s['rougeL'].fmeasure for s in scores])\n",
    "  # return np.mean([s['rouge1'].fmeasure for s in scores]), \\\n",
    "  #        np.mean([s['rouge2'].fmeasure for s in scores]), \\\n",
    "  #        np.mean([s['rougeLsum'].fmeasure for s in scores])\n",
    "  return [str(s['rougeLsum'].fmeasure) for s in scores]\n",
    "\n",
    "def read_file_lines(path):\n",
    "  with open(path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "  if path.endswith('.jsonl'):\n",
    "    lines = [json.loads(line) for line in lines]\n",
    "  return lines\n",
    "\n",
    "def evaluate(preds, refs):\n",
    "  return calc_rouge(preds, refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "with open('./qa_pairs/predict/plos/pls_qa.txt', 'r', encoding=\"utf-8\") as f:\n",
    "    # lines = f.readlines()[:100]\n",
    "    for lid, line in enumerate(f.readlines()[:100]):\n",
    "        line = re.sub(r'\\b\\d+:', '\\nQuestion:', line.split('\\t')[-1]).replace('Answer:',\" Answer:\").strip()\n",
    "        preds_ = [pred.replace(\"Question: \",\"\").replace(\"Answer: \",\"\") for pred in line.split(\"\\n\")]\n",
    "        assert len(preds_) == 10\n",
    "        # refs_ = [merge_spaces(gdatas[lid]['plain language summary'].replace('\\n',' ')).strip()] * 10\n",
    "        refs_ = [merge_spaces(gdatas[lid]['abstract'].replace('\\n',' ')).strip()] * 10\n",
    "        scores = evaluate(preds_, refs_)\n",
    "        with open(\"./qa_pairs/predict/plos/pls_qa_scores.txt\",\"a+\") as f:\n",
    "            f.write(\"\\t\".join(scores) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### involking LLM API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for summary generation\n",
    "\n",
    "import time\n",
    "import openai\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version =  \n",
    "openai.api_base = \"https://gpt4apidutir.openai.azure.com/\"  # Your Azure OpenAI resource's endpoint value.\n",
    "openai.api_key = \n",
    "\n",
    "# t_sum = 0\n",
    "\n",
    "with open('./datasets/plos/test_elife.jsonl', 'r', encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "    for lid in tqdm(range(241)):\n",
    "        data = json.loads(lines[lid])\n",
    "        # context = data['article'].replace('\\n',' ').strip()\n",
    "        context = ' '.join(data['article'].replace('\\n',' ').strip().split(\" \"))\n",
    "        # print(len(context.split(\" \")))\n",
    "\n",
    "        conversation=[\n",
    "            {\"role\": \"user\", \"content\": \"Below is a paper. \\n {} \\n Please give me a layman summary start with [L] and an expert summary start with [E] of this paper in one paragraph seperately.\".format(context)},\n",
    "            ]\n",
    "                \n",
    "        response = openai.ChatCompletion.create(\n",
    "            engine=\"\", # The deployment name you chose when you deployed the GPT-35-16k or GPT-4-turbo model.\n",
    "            messages=conversation\n",
    "        )\n",
    "\n",
    "\n",
    "        with open('', 'a+', encoding='utf-8') as f:\n",
    "            f.write(data['doi'] + '\\t' + response['choices'][0]['message']['content'].strip().replace('\\n','') + '\\n')\n",
    "               \n",
    "        time.sleep(15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for qa pairs generation\n",
    "\n",
    "datas = []\n",
    "with open('./datasets/plos/test_plos.jsonl', 'r', encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "    # print(len(lines)) 26214\n",
    "    for lid in range(len(lines)):\n",
    "        datas.append(json.loads(lines[lid]))\n",
    "\n",
    "for nid, data in enumerate(tqdm(datas)):\n",
    "    \n",
    "    for id in range(2):\n",
    "\n",
    "        # summary = data[id]\n",
    "        # conversation=[\n",
    "        # {\"role\": \"user\", \"content\": \"Generate five answerable and specific questions based on the following context. Context: {} \\n and give me the answers of them\".format(summary)},\n",
    "        # ]\n",
    "        if id % 2 == 1:\n",
    "            summary = merge_spaces(data[\"plain language summary\"].replace('\\n',' ')).strip()\n",
    "        else:\n",
    "            summary = merge_spaces(data[\"abstract\"].replace('\\n',' ')).strip()\n",
    "\n",
    "        conversation=[\n",
    "        {\"role\": \"user\", \"content\": \"Text: {} \\n Given the above text, please propose 10 English questions that are diverse and cover all parts of the text, in the following format: \\\"1: \\\", \\\"2: \\\", ..., and give me the answer of each question.\".format(summary)},\n",
    "        ]\n",
    "\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            engine=\"\",\n",
    "            messages=conversation\n",
    "        )\n",
    "\n",
    "\n",
    "        if id % 2 == 1:\n",
    "            with open('', 'a+', encoding='utf-8') as f:\n",
    "                f.write(data['doi'] + '\\t' + response['choices'][0]['message']['content'].replace('\\n','') + '\\n')\n",
    "        else:\n",
    "            with open('', 'a+', encoding='utf-8') as f:\n",
    "                f.write(data['doi'] + '\\t' + response['choices'][0]['message']['content'].replace('\\n','') + '\\n')\n",
    "      \n",
    "    if nid % 3 == 0 and nid != 0:\n",
    "        time.sleep(10)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
